\section{Evaluation}

We build a map-reduce simulator that evaluates the performance of our
bandwidth-aware placement algorithm using Facebook workload in 2009 provided by
the SWIM benchmark~\cite{SWIM13} under multiple network topology; Fat-Tree,
Jellyfish and a slight modification to Jellyfish in which with 50\% and 25\%
probability, a node will be connected to 1 and 3 additional switches
respectively which will be referred to from this point as Jellyfish2.

In each of the graphs below will be labeled in the format $<routingStrategy>\
<numMR>$.  $<routingStrategy>$ might be one of three things;  RR indicates
random routing (i.e. both placements and routings are being done at random),
HAR indicates simulated annealing for routing decisions, while HAR2 indicates
simulated annealing for both placement and routing decisions.  $<numMR>$
indicates the number of mappers and reducers that each job will request in the
beginning of their execution.

All of the experiments are run on a 4-core 2.50 GHz processor. The bandwidth of
each link is set to 100Mbps. Section~\ref{sec:throughput} evaluates the
throughput of jobs using our algorithm while section~\ref{sec:completionTime}
evaluates the jobs' completion time. Since we have two levels of SA, we will
also show the benefits provided by each level.

\subsection{Throughput}
\label{sec:throughput}

\begin{figure}
  \includegraphics[width=\linewidth]{./figs/jf2_throughput.png}
  \caption{Throughput in Jellyfish2 with varied routing strategies}
  \label{fig:jf2_throughput}
\end{figure}

\begin{figure}
  \includegraphics[width=\linewidth]{./figs/jf_throughput.png}
  \caption{Throughput in Jellyfish with varied routing strategies}
  \label{fig:jf_throughput}
\end{figure}

\begin{figure}
  \includegraphics[width=\linewidth]{./figs/ft_throughput.png}
  \caption{Throughput in Fat-Tree with varied routing strategies}
  \label{fig:ft_throughput}
\end{figure}

In Jellyfish and Fat-Tree, the throughput improvement provided by SA
for routing decisions is ~11\% and for routing and placement decisions is
~14\% when the number of hosts is 45 as opposed to random routing. The
improvement decreases to almost 0 when we set the number of hosts to
100. This is due to the fact that the throughput is bottlenecked by the
link connecting host nodes with the switch. For instance, if the number of
mappers and reducers are each set to 2, the upper-limit in normal Jellyfish and
Fat-Tree topology will only be $2 * linkBandwidth$ while optimally, it should
be $2 * 2 * linkBandwidth$. As the graph shows, both one level and two levels
of SA quickly hits the upper-bound on the total amount bandwidth of the graph.

However, the throughput improvements are significantly better in Jellyfish2
since the aforementioned bottleneck is reduced as some nodes could be directly
connected to as many as 4 switches instead of just one. As shown in the graph,
the throughput improvement provided by each level of SA is constant (15\%) as
we scale the number of hosts;

\note{Thought: Start thinking about how data is being moved around as opposed
to just focusing on shuffle phase?} \newline \note{Thought: Evaluate with
varying map-reduce tasks?}

\subsection{Completion Time}
\label{sec:completionTime}

\begin{figure}
  \includegraphics[width=\linewidth]{./figs/jf2_ct.png}
  \caption{Jobs completion time in Jellyfish2 with varied routing strategies}
  \label{fig:jf2_throughput}
\end{figure}

\begin{figure}
  \includegraphics[width=\linewidth]{./figs/jf_ct.png}
  \caption{Jobs completion time in Jellyfish with varied routing strategies}
  \label{fig:jf_throughput}
\end{figure}

\begin{figure}
  \includegraphics[width=\linewidth]{./figs/ft_ct.png}
  \caption{Jobs completion time in Fat-Tree with varied routing strategies}
  \label{fig:ft_throughput}
\end{figure}

\todo{Separate into bins?}
